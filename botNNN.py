import os
import logging
import requests
import asyncio
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import Application, CommandHandler, CallbackQueryHandler, ContextTypes
from bs4 import BeautifulSoup
from starlette.applications import Starlette
from starlette.routing import Route
from starlette.requests import Request
from starlette.responses import Response, PlainTextResponse
import uvicorn

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≤–µ–±—Ö—É–∫–∞ –¥–ª—è Render
TOKEN = os.environ["BOT_TOKEN"]  # –¢–æ–∫–µ–Ω –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
PORT = int(os.environ.get("PORT", 8000))
WEBHOOK_URL = os.environ.get("RENDER_EXTERNAL_URL", "") + "/webhook"

# –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ Telegram
application = Application.builder().token(TOKEN).build()

class NewsParser:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π —Å —Ä–µ–∑–µ—Ä–≤–Ω—ã–º–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏"""
    
    def __init__(self):
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        }
        logger.info("üîÑ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —É–ª—É—á—à–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π")
    
    def parse_ria_news(self, max_news: int = 5) -> list:
        """–ü–∞—Ä—Å–∏–Ω–≥ –Ω–æ–≤–æ—Å—Ç–µ–π —Å RIA.ru"""
        try:
            url = "https://ria.ru/"
            response = requests.get(url, headers=self.headers, timeout=15)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            news_items = []
            
            # –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è RIA
            articles = soup.select('[data-type="article"], .cell-list__item, .list-item, article')[:max_news*2]
            
            for article in articles:
                try:
                    title_elem = article.select_one('.cell-list__item-title, .list-item__title, h2, h3')
                    if not title_elem:
                        continue
                    
                    title = title_elem.get_text(strip=True)
                    if len(title) < 10:
                        continue
                    
                    link_elem = article.find('a', href=True)
                    if link_elem:
                        link = link_elem['href']
                        if link and not link.startswith('http'):
                            link = 'https://ria.ru' + link
                    else:
                        continue
                    
                    news_items.append({
                        'title': title[:150],
                        'link': link,
                        'source': 'RIA –ù–æ–≤–æ—Å—Ç–∏'
                    })
                    
                    if len(news_items) >= max_news:
                        break
                        
                except Exception as e:
                    continue
            
            logger.info(f"‚úÖ RIA: –ø–æ–ª—É—á–µ–Ω–æ {len(news_items)} –Ω–æ–≤–æ—Å—Ç–µ–π")
            return news_items
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ RIA: {e}")
            return []
    
    def parse_tass_news(self, max_news: int = 5) -> list:
        """–ü–∞—Ä—Å–∏–Ω–≥ –Ω–æ–≤–æ—Å—Ç–µ–π —Å TASS.ru"""
        try:
            url = "https://tass.ru/"
            response = requests.get(url, headers=self.headers, timeout=15)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            news_items = []
            
            articles = soup.select('.news-card, .news-line__item, [data-io-article-url]')[:max_news*2]
            
            for article in articles:
                try:
                    title_elem = article.select_one('.news-card__title, .news-line__item-title, h3')
                    if not title_elem:
                        continue
                    
                    title = title_elem.get_text(strip=True)
                    if len(title) < 10:
                        continue
                    
                    link_elem = article.find('a', href=True)
                    if link_elem:
                        link = link_elem['href']
                        if link and not link.startswith('http'):
                            link = 'https://tass.ru' + link
                    else:
                        # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å —Å—Å—ã–ª–∫—É –∏–∑ data-–∞—Ç—Ä–∏–±—É—Ç–∞
                        link = article.get('data-io-article-url', '')
                        if link and not link.startswith('http'):
                            link = 'https://tass.ru' + link
                    
                    if not link:
                        continue
                    
                    news_items.append({
                        'title': title[:150],
                        'link': link,
                        'source': '–¢–ê–°–°'
                    })
                    
                    if len(news_items) >= max_news:
                        break
                        
                except Exception as e:
                    continue
            
            logger.info(f"‚úÖ –¢–ê–°–°: –ø–æ–ª—É—á–µ–Ω–æ {len(news_items)} –Ω–æ–≤–æ—Å—Ç–µ–π")
            return news_items
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –¢–ê–°–°: {e}")
            return []
    
    def parse_belpressa_news(self, max_news: int = 5) -> list:
        """–ü–∞—Ä—Å–∏–Ω–≥ –Ω–æ–≤–æ—Å—Ç–µ–π –ë–µ–ª–≥–æ—Ä–æ–¥–∞ —Å Belpressa.ru"""
        try:
            url = "https://www.belpressa.ru/news/"
            response = requests.get(url, headers=self.headers, timeout=15)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            news_items = []
            
            # –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã
            articles = soup.select('.news-item, article, .item, .news-list__item')[:max_news*3]
            
            for article in articles:
                try:
                    title_elem = article.select_one('h2, h3, .title, .news-title')
                    if not title_elem:
                        continue
                    
                    title = title_elem.get_text(strip=True)
                    if len(title) < 15:
                        continue
                    
                    link_elem = article.find('a', href=True)
                    if link_elem:
                        link = link_elem['href']
                        if link and not link.startswith('http'):
                            link = 'https://www.belpressa.ru' + link
                    else:
                        continue
                    
                    news_items.append({
                        'title': title[:200],
                        'link': link,
                        'source': '–ë–µ–ª–ü—Ä–µ—Å—Å–∞'
                    })
                    
                    if len(news_items) >= max_news:
                        break
                        
                except Exception as e:
                    continue
            
            # –†–µ–∑–µ—Ä–≤–Ω—ã–π –º–µ—Ç–æ–¥ –ø–æ–∏—Å–∫–∞
            if not news_items:
                all_links = soup.find_all('a', href=True)
                news_count = 0
                for link in all_links:
                    href = link['href']
                    if '/news/' in href and any(x in href for x in ['2024', '2025']):
                        title = link.get_text(strip=True)
                        if title and len(title) > 20:
                            full_link = href if href.startswith('http') else 'https://www.belpressa.ru' + href
                            news_items.append({
                                'title': title[:200],
                                'link': full_link,
                                'source': '–ë–µ–ª–ü—Ä–µ—Å—Å–∞'
                            })
                            news_count += 1
                            if news_count >= max_news:
                                break
            
            logger.info(f"‚úÖ –ë–µ–ª–ü—Ä–µ—Å—Å–∞: –ø–æ–ª—É—á–µ–Ω–æ {len(news_items)} –Ω–æ–≤–æ—Å—Ç–µ–π")
            return news_items
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ë–µ–ª–ü—Ä–µ—Å—Å–∞: {e}")
            return []
    
    def parse_belru_news(self, max_news: int = 5) -> list:
        """–ü–∞—Ä—Å–∏–Ω–≥ –Ω–æ–≤–æ—Å—Ç–µ–π –ë–µ–ª–≥–æ—Ä–æ–¥–∞ —Å Bel.ru"""
        try:
            url = "https://bel.ru/news/"
            response = requests.get(url, headers=self.headers, timeout=15)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            news_items = []
            
            articles = soup.select('.news-item, article, .item, [class*="news"]')[:max_news*3]
            
            for article in articles:
                try:
                    title_elem = article.select_one('h1, h2, h3, h4, .title, .news-title')
                    if not title_elem:
                        continue
                    
                    title = title_elem.get_text(strip=True)
                    if len(title) < 15:
                        continue
                    
                    link_elem = article.find('a', href=True)
                    if link_elem:
                        link = link_elem['href']
                        if link and not link.startswith('http'):
                            link = 'https://bel.ru' + link
                    else:
                        continue
                    
                    news_items.append({
                        'title': title[:200],
                        'link': link,
                        'source': '–ë–µ–ª.–†—É'
                    })
                    
                    if len(news_items) >= max_news:
                        break
                        
                except Exception as e:
                    continue
            
            logger.info(f"‚úÖ –ë–µ–ª.–†—É: –ø–æ–ª—É—á–µ–Ω–æ {len(news_items)} –Ω–æ–≤–æ—Å—Ç–µ–π")
            return news_items
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ë–µ–ª.–†—É: {e}")
            return []
    
    def parse_alternative_belgorod_news(self, max_news: int = 5) -> list:
        """–†–µ–∑–µ—Ä–≤–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –Ω–æ–≤–æ—Å—Ç–µ–π –ë–µ–ª–≥–æ—Ä–æ–¥–∞"""
        try:
            news_items = []
            
            # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫ - —Ä–µ–≥–∏–æ–Ω–∞–ª—å–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏
            alternative_sources = [
                {
                    'url': 'https://www.belnovosti.ru/',
                    'source': '–ë–µ–ª–ù–æ–≤–æ—Å—Ç–∏',
                    'base': 'https://www.belnovosti.ru'
                }
            ]
            
            for source in alternative_sources:
                try:
                    response = requests.get(source['url'], headers=self.headers, timeout=10)
                    soup = BeautifulSoup(response.text, 'html.parser')
                    
                    # –ò—â–µ–º –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
                    all_links = soup.find_all('a', href=True)
                    for link in all_links:
                        href = link['href']
                        title = link.get_text(strip=True)
                        
                        if (title and len(title) > 20 and 
                            any(word in title.lower() for word in ['–±–µ–ª–≥–æ—Ä–æ–¥', '–æ–±–ª–∞—Å—Ç', '–≥–æ—Ä–æ–¥', '–Ω–æ–≤–æ—Å—Ç'])):
                            
                            full_link = href if href.startswith('http') else source['base'] + href
                            news_items.append({
                                'title': title[:150],
                                'link': full_link,
                                'source': source['source']
                            })
                            
                            if len(news_items) >= max_news:
                                break
                                
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ {source['source']}: {e}")
                    continue
            
            return news_items
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {e}")
            return []

# –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä –ø–∞—Ä—Å–µ—Ä–∞
news_parser = NewsParser()

# ===== –û–ë–†–ê–ë–û–¢–ß–ò–ö–ò –ö–û–ú–ê–ù–î –¢–ï–õ–ï–ì–†–ê–ú =====
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–º–∞–Ω–¥—ã /start"""
    keyboard = [
        [InlineKeyboardButton("üá∑üá∫ –§–µ–¥–µ—Ä–∞–ª—å–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏", callback_data="federal_news")],
        [InlineKeyboardButton("üèôÔ∏è –ù–æ–≤–æ—Å—Ç–∏ –ë–µ–ª–≥–æ—Ä–æ–¥–∞", callback_data="belgorod_news")],
        [InlineKeyboardButton("üîÑ –û–±–Ω–æ–≤–∏—Ç—å", callback_data="refresh_news"),
         InlineKeyboardButton("‚ÑπÔ∏è –ü–æ–º–æ—â—å", callback_data="help")]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    user = update.effective_user
    welcome_text = (
        f"üëã –ü—Ä–∏–≤–µ—Ç, {user.first_name}!\n\n"
        "üì∞ *–Ø –≤–∞—à –Ω–æ–≤–æ—Å—Ç–Ω–æ–π –±–æ—Ç*\n\n"
        "–Ø –ø–æ–º–æ–≥—É –≤–∞–º –±—ã—Ç—å –≤ –∫—É—Ä—Å–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–æ–±—ã—Ç–∏–π:\n"
        "‚Ä¢ üá∑üá∫ –§–µ–¥–µ—Ä–∞–ª—å–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ –†–æ—Å—Å–∏–∏\n" 
        "‚Ä¢ üèôÔ∏è –ù–æ–≤–æ—Å—Ç–∏ –ë–µ–ª–≥–æ—Ä–æ–¥–∞ –∏ –æ–±–ª–∞—Å—Ç–∏\n\n"
        "–í—ã–±–µ—Ä–∏—Ç–µ –∫–∞—Ç–µ–≥–æ—Ä–∏—é:"
    )
    
    await update.message.reply_text(
        welcome_text,
        reply_markup=reply_markup,
        parse_mode='Markdown'
    )

async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–º–∞–Ω–¥—ã /help"""
    help_text = (
        "‚ÑπÔ∏è *–ü–æ–º–æ—â—å –ø–æ –±–æ—Ç—É*\n\n"
        "*–û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:*\n"
        "/start - –Ω–∞—á–∞—Ç—å —Ä–∞–±–æ—Ç—É\n"
        "/news - –ø–æ–ª—É—á–∏—Ç—å –Ω–æ–≤–æ—Å—Ç–∏\n"
        "/help - —ç—Ç–∞ —Å–ø—Ä–∞–≤–∫–∞\n\n"
        "*–ò—Å—Ç–æ—á–Ω–∏–∫–∏ –Ω–æ–≤–æ—Å—Ç–µ–π:*\n"
        "‚Ä¢ RIA –ù–æ–≤–æ—Å—Ç–∏ - —Ñ–µ–¥–µ—Ä–∞–ª—å–Ω—ã–µ\n"
        "‚Ä¢ –¢–ê–°–° - —Ñ–µ–¥–µ—Ä–∞–ª—å–Ω—ã–µ\n" 
        "‚Ä¢ –ë–µ–ª–ü—Ä–µ—Å—Å–∞ - –ë–µ–ª–≥–æ—Ä–æ–¥\n"
        "‚Ä¢ –ë–µ–ª.–†—É - –ë–µ–ª–≥–æ—Ä–æ–¥\n\n"
        "üìû *–ü–æ–¥–¥–µ—Ä–∂–∫–∞:* @Alex_De_White"
    )
    
    keyboard = [[InlineKeyboardButton("üè† –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é", callback_data="refresh_news")]]
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    await update.message.reply_text(
        help_text,
        reply_markup=reply_markup,
        parse_mode='Markdown'
    )

async def news_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–º–∞–Ω–¥—ã /news"""
    keyboard = [
        [InlineKeyboardButton("üá∑üá∫ –§–µ–¥–µ—Ä–∞–ª—å–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏", callback_data="federal_news")],
        [InlineKeyboardButton("üèôÔ∏è –ù–æ–≤–æ—Å—Ç–∏ –ë–µ–ª–≥–æ—Ä–æ–¥–∞", callback_data="belgorod_news")]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    await update.message.reply_text(
        "üì∞ –í—ã–±–µ—Ä–∏—Ç–µ –∫–∞—Ç–µ–≥–æ—Ä–∏—é –Ω–æ–≤–æ—Å—Ç–µ–π:",
        reply_markup=reply_markup
    )

# ===== –û–ë–†–ê–ë–û–¢–ß–ò–ö –ö–ù–û–ü–û–ö =====
async def button_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞–∂–∞—Ç–∏–π –Ω–∞ –∫–Ω–æ–ø–∫–∏"""
    query = update.callback_query
    await query.answer()
    
    data = query.data
    
    if data == "federal_news":
        await send_federal_news(query)
    elif data == "belgorod_news":
        await send_belgorod_news(query)
    elif data == "refresh_news":
        await refresh_news_menu(query)
    elif data == "help":
        await show_help(query)

async def send_federal_news(query):
    """–û—Ç–ø—Ä–∞–≤–∫–∞ —Ñ–µ–¥–µ—Ä–∞–ª—å–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π"""
    await query.edit_message_text("üì° *–ó–∞–≥—Ä—É–∂–∞—é —Ñ–µ–¥–µ—Ä–∞–ª—å–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏...*", parse_mode='Markdown')
    
    # –ü–∞—Ä—Å–∏–º –Ω–æ–≤–æ—Å—Ç–∏ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ
    ria_news = await asyncio.get_event_loop().run_in_executor(None, news_parser.parse_ria_news, 4)
    tass_news = await asyncio.get_event_loop().run_in_executor(None, news_parser.parse_tass_news, 4)
    
    all_news = ria_news + tass_news
    
    if not all_news:
        message = (
            "‚ùå *–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–µ–¥–µ—Ä–∞–ª—å–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏*\n\n"
            "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ:\n"
            "‚Ä¢ –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-—Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ\n" 
            "‚Ä¢ –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –ø–æ–∑–∂–µ\n"
            "‚Ä¢ –ù–∞–ø–∏—Å–∞—Ç—å –≤ –ø–æ–¥–¥–µ—Ä–∂–∫—É @Alex_De_White"
        )
    else:
        message = "üá∑üá∫ *–§–ï–î–ï–†–ê–õ–¨–ù–´–ï –ù–û–í–û–°–¢–ò*\n\n"
        for i, news in enumerate(all_news[:6], 1):
            message += f"*{i}. {news['source']}*\n"
            message += f"{news['title']}\n"
            message += f"[–ß–∏—Ç–∞—Ç—å]({news['link']})\n\n"
    
    keyboard = [
        [InlineKeyboardButton("üîÑ –û–±–Ω–æ–≤–∏—Ç—å", callback_data="federal_news")],
        [InlineKeyboardButton("üèôÔ∏è –ù–æ–≤–æ—Å—Ç–∏ –ë–µ–ª–≥–æ—Ä–æ–¥–∞", callback_data="belgorod_news")],
        [InlineKeyboardButton("üè† –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é", callback_data="refresh_news")]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    await query.edit_message_text(
        message,
        reply_markup=reply_markup,
        parse_mode='Markdown',
        disable_web_page_preview=False
    )

async def send_belgorod_news(query):
    """–û—Ç–ø—Ä–∞–≤–∫–∞ –Ω–æ–≤–æ—Å—Ç–µ–π –ë–µ–ª–≥–æ—Ä–æ–¥–∞ —Å —Ä–µ–∑–µ—Ä–≤–Ω—ã–º–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏"""
    await query.edit_message_text("üì° *–ó–∞–≥—Ä—É–∂–∞—é –Ω–æ–≤–æ—Å—Ç–∏ –ë–µ–ª–≥–æ—Ä–æ–¥–∞...*", parse_mode='Markdown')
    
    # –ü–∞—Ä—Å–∏–º –æ—Å–Ω–æ–≤–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
    belpressa_news = await asyncio.get_event_loop().run_in_executor(None, news_parser.parse_belpressa_news, 3)
    belru_news = await asyncio.get_event_loop().run_in_executor(None, news_parser.parse_belru_news, 3)
    
    all_news = belpressa_news + belru_news
    
    # –ï—Å–ª–∏ –æ—Å–Ω–æ–≤–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –Ω–µ –¥–∞–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∑–µ—Ä–≤–Ω—ã–µ
    if not all_news:
        await query.edit_message_text("üì° *–ò—â—É –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏...*", parse_mode='Markdown')
        alternative_news = await asyncio.get_event_loop().run_in_executor(None, news_parser.parse_alternative_belgorod_news, 6)
        all_news = alternative_news
    
    if not all_news:
        message = (
            "‚ùå *–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–æ–≤–æ—Å—Ç–∏ –ë–µ–ª–≥–æ—Ä–æ–¥–∞*\n\n"
            "–í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:\n"
            "‚Ä¢ –°–∞–π—Ç—ã –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã\n"
            "‚Ä¢ –ò–∑–º–µ–Ω–∏–ª–∞—Å—å —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ —Å–∞–π—Ç–æ–≤\n"
            "‚Ä¢ –ü—Ä–æ–±–ª–µ–º—ã —Å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ–º\n\n"
            "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ –∏–ª–∏ –ø—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–µ–¥–µ—Ä–∞–ª—å–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ üá∑üá∫"
        )
    else:
        message = "üèôÔ∏è *–ù–û–í–û–°–¢–ò –ë–ï–õ–ì–û–†–û–î–ê –ò –û–ë–õ–ê–°–¢–ò*\n\n"
        for i, news in enumerate(all_news[:6], 1):
            message += f"*{i}. {news['source']}*\n"
            message += f"{news['title']}\n"
            message += f"[–ß–∏—Ç–∞—Ç—å]({news['link']})\n\n"
        
        if not belpressa_news and not belru_news:
            message += "‚ö†Ô∏è *–ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏*\n"
    
    keyboard = [
        [InlineKeyboardButton("üîÑ –û–±–Ω–æ–≤–∏—Ç—å", callback_data="belgorod_news")],
        [InlineKeyboardButton("üá∑üá∫ –§–µ–¥–µ—Ä–∞–ª—å–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏", callback_data="federal_news")],
        [InlineKeyboardButton("üè† –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é", callback_data="refresh_news")]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    await query.edit_message_text(
        message,
        reply_markup=reply_markup,
        parse_mode='Markdown',
        disable_web_page_preview=False
    )

async def refresh_news_menu(query):
    """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≥–ª–∞–≤–Ω–æ–≥–æ –º–µ–Ω—é"""
    keyboard = [
        [InlineKeyboardButton("üá∑üá∫ –§–µ–¥–µ—Ä–∞–ª—å–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏", callback_data="federal_news")],
        [InlineKeyboardButton("üèôÔ∏è –ù–æ–≤–æ—Å—Ç–∏ –ë–µ–ª–≥–æ—Ä–æ–¥–∞", callback_data="belgorod_news")],
        [InlineKeyboardButton("üîÑ –û–±–Ω–æ–≤–∏—Ç—å", callback_data="refresh_news"),
         InlineKeyboardButton("‚ÑπÔ∏è –ü–æ–º–æ—â—å", callback_data="help")]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    await query.edit_message_text(
        "üì∞ *–ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é*\n\n"
        "–í—ã–±–µ—Ä–∏—Ç–µ –∫–∞—Ç–µ–≥–æ—Ä–∏—é –Ω–æ–≤–æ—Å—Ç–µ–π:",
        reply_markup=reply_markup,
        parse_mode='Markdown'
    )

async def show_help(query):
    """–ü–æ–∫–∞–∑ —Å–ø—Ä–∞–≤–∫–∏"""
    help_text = (
        "‚ÑπÔ∏è *–ü–æ–º–æ—â—å –ø–æ –±–æ—Ç—É*\n\n"
        "*–ò—Å—Ç–æ—á–Ω–∏–∫–∏ –Ω–æ–≤–æ—Å—Ç–µ–π:*\n"
        "‚Ä¢ RIA –ù–æ–≤–æ—Å—Ç–∏ - —Ñ–µ–¥–µ—Ä–∞–ª—å–Ω—ã–µ\n"
        "‚Ä¢ –¢–ê–°–° - —Ñ–µ–¥–µ—Ä–∞–ª—å–Ω—ã–µ\n"
        "‚Ä¢ –ë–µ–ª–ü—Ä–µ—Å—Å–∞ - –ë–µ–ª–≥–æ—Ä–æ–¥\n" 
        "‚Ä¢ –ë–µ–ª.–†—É - –ë–µ–ª–≥–æ—Ä–æ–¥\n\n"
        "*–ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:*\n"
        "1. –í—ã–±–µ—Ä–∏—Ç–µ –∫–∞—Ç–µ–≥–æ—Ä–∏—é –Ω–æ–≤–æ—Å—Ç–µ–π\n"
        "2. –ù–∞–∂–º–∏—Ç–µ –Ω–∞ —Å—Å—ã–ª–∫—É –¥–ª—è —á—Ç–µ–Ω–∏—è\n"
        "3. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ 'üîÑ –û–±–Ω–æ–≤–∏—Ç—å' –¥–ª—è –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π\n\n"
        "üìû *–ü–æ–¥–¥–µ—Ä–∂–∫–∞:* @Alex_De_White"
    )
    
    keyboard = [
        [InlineKeyboardButton("üá∑üá∫ –§–µ–¥–µ—Ä–∞–ª—å–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏", callback_data="federal_news")],
        [InlineKeyboardButton("üèôÔ∏è –ù–æ–≤–æ—Å—Ç–∏ –ë–µ–ª–≥–æ—Ä–æ–¥–∞", callback_data="belgorod_news")],
        [InlineKeyboardButton("üè† –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é", callback_data="refresh_news")]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    await query.edit_message_text(
        help_text,
        reply_markup=reply_markup,
        parse_mode='Markdown'
    )

# ===== –í–ï–ë–•–£–ö –≠–ù–î–ü–û–ò–ù–¢–´ –î–õ–Ø RENDER =====
async def webhook(request: Request) -> Response:
    """–≠–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –≤–µ–±—Ö—É–∫–æ–≤ –æ—Ç Telegram"""
    try:
        data = await request.json()
        update = Update.de_json(data, application.bot)
        await application.update_queue.put(update)
        return Response()
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –≤–µ–±—Ö—É–∫–µ: {e}")
        return Response(status_code=500)

async def health_check(request: Request) -> PlainTextResponse:
    """–≠–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∑–¥–æ—Ä–æ–≤—å—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    return PlainTextResponse("‚úÖ –ë–æ—Ç —Ä–∞–±–æ—Ç–∞–µ—Ç")

async def set_webhook():
    """–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤–µ–±—Ö—É–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ"""
    if WEBHOOK_URL:
        try:
            await application.bot.set_webhook(url=f"{WEBHOOK_URL}")
            logger.info(f"‚úÖ –í–µ–±—Ö—É–∫ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: {WEBHOOK_URL}")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –≤–µ–±—Ö—É–∫–∞: {e}")
    else:
        logger.warning("‚ö†Ô∏è RENDER_EXTERNAL_URL –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –≤–µ–±—Ö—É–∫ –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω")

# ===== –†–ï–ì–ò–°–¢–†–ê–¶–ò–Ø –û–ë–†–ê–ë–û–¢–ß–ò–ö–û–í =====
def setup_handlers():
    """–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –≤—Å–µ—Ö –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤"""
    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("help", help_command))
    application.add_handler(CommandHandler("news", news_command))
    application.add_handler(CallbackQueryHandler(button_handler))

# ===== –ó–ê–ü–£–°–ö –ü–†–ò–õ–û–ñ–ï–ù–ò–Ø =====
async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–ø—É—Å–∫–∞"""
    logger.info("üîÑ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –Ω–æ–≤–æ—Å—Ç–Ω–æ–≥–æ –±–æ—Ç–∞...")
    
    # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏
    setup_handlers()
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
    await application.initialize()
    await application.start()
    
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤–µ–±—Ö—É–∫
    await set_webhook()
    
    # –°–æ–∑–¥–∞–µ–º Starlette –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
    starlette_app = Starlette(routes=[
        Route("/webhook", webhook, methods=["POST"]),
        Route("/healthcheck", health_check, methods=["GET"]),
        Route("/", health_check, methods=["GET"]),
    ])
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º —Å–µ—Ä–≤–µ—Ä
    config = uvicorn.Config(
        app=starlette_app,
        host="0.0.0.0",
        port=PORT,
        log_level="info"
    )
    server = uvicorn.Server(config)
    
    logger.info(f"‚úÖ –ù–æ–≤–æ—Å—Ç–Ω–æ–π –±–æ—Ç –∑–∞–ø—É—â–µ–Ω –Ω–∞ –ø–æ—Ä—Ç—É {PORT}")
    logger.info("ü§ñ –ë–æ—Ç –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!")
    
    await server.serve()

if __name__ == "__main__":
    asyncio.run(main())
